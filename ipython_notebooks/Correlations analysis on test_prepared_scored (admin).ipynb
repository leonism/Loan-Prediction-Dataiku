{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.10"
    },
    "analyzedDataset": "test_prepared_scored",
    "creator": "admin",
    "tags": [],
    "customFields": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analyzing correlations betweeen variables in test_prepared_scored\n",
        "\n",
        "In this notebook, we are going to study the correlations.\n",
        "\n",
        "* [Setup and loading the data](#setup)\n",
        "* [Correlation matrix](#corr-matrix)\n",
        "* [Scatterplot matrix](#scatter-matrix)\n",
        "* [Detailed analysis between two variables](#two-vars)\n",
        "\n",
        "\u003ccenter\u003e\u003cstrong\u003eSelect Cell \u003e Run All to execute the whole analysis\u003c/strong\u003e\u003c/center\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and dataset loading \u003ca id\u003d\"setup\" /\u003e \n",
        "\n",
        "First of all, let\u0027s load the libraries that we\u0027ll use"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "%pylab inline\n",
        "import dataiku                          # Access to Dataiku datasets\n",
        "import pandas as pd, numpy as np        # Data manipulation \n",
        "import scipy.cluster.hierarchy as sch   # Used for reordering the correlation matrix\n",
        "import seaborn as sns                   # Graphing\n",
        "sns.set(style\u003d\"white\")                  # Tuning the style of charts\n",
        "import warnings                         # Disable some warnings\n",
        "warnings.filterwarnings(\"ignore\",category\u003dDeprecationWarning)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first thing we do is now to load the dataset and put aside the three main types of columns:\n",
        "\n",
        "* Numerics\n",
        "* Categorical\n",
        "* Dates\n",
        "\n",
        "Since analyzing correlations requires to have the data in memory, we are only going to load a sample of the data. Modify the following cell to change the size of the sample."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Take a handle on the dataset\n",
        "mydataset \u003d dataiku.Dataset(\"test_prepared_scored\")\n",
        "\n",
        "# Load the first 100\u0027000 lines.\n",
        "# You can also load random samples, limit yourself to some columns, or only load\n",
        "# data matching some filters.\n",
        "#\n",
        "# Please refer to the Dataiku Python API documentation for more information\n",
        "df \u003d mydataset.get_dataframe(\n",
        "    limit \u003d 100000)\n",
        "\n",
        "# Get the column names\n",
        "numerical_columns \u003d list(df.select_dtypes(include\u003d[np.number]).columns)\n",
        "categorical_columns \u003d list(df.select_dtypes(include\u003d[object]).columns)\n",
        "date_columns \u003d list(df.select_dtypes(include\u003d[\u0027\u003cM8[ns]\u0027]).columns)\n",
        "\n",
        "# Print a quick summary of what we just loaded\n",
        "print \"Loaded dataset\"\n",
        "print \"   Rows: %s\" % df.shape[0]\n",
        "print \"   Columns: %s (%s num, %s cat, %s date)\" % (df.shape[1], \n",
        "                                                    len(numerical_columns), len(categorical_columns),\n",
        "                                                    len(date_columns))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation matrix \u003ca id\u003d\"corr-matrix\" /\u003e\n",
        "\n",
        "The very first correlation analysis consists of plotting the \"Correlation matrix\" for numerical variables.\n",
        "\n",
        "For each couple of numerical variables, this computes the \"strength\" of the correlation (called the Pearson coefficient):\n",
        "\n",
        " * 1.0 means a perfect correlation\n",
        " * 0.0 means no correlation\n",
        " * -1.0 means a perfect \"inverse\" correlation\n",
        " \n",
        "Since it does not really make sense to print this correlation plot for hundred of variables, we are restricting it to the first 50 numerical variables of the dataset. Modify the following cell to change this"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Select variables to plot for the correlation matrix\n",
        "corr_matrix_vars \u003d numerical_columns[0:50]\n",
        "\n",
        "print \"Plotting the correlation matrix on the following variables : %s\" % corr_matrix_vars"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Only select the requested columns\n",
        "df_corr_matrix \u003d df[corr_matrix_vars]\n",
        "\n",
        "# This computes the Pearson coefficient for all couples\n",
        "corr \u003d df_corr_matrix.corr().fillna(0)\n",
        "\n",
        "# Start drawing\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask \u003d np.zeros_like(corr, dtype\u003dnp.bool)\n",
        "mask[np.triu_indices_from(mask)] \u003d True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "size \u003d max(10, len(corr.columns)/2.)\n",
        "f, ax \u003d plt.subplots(figsize\u003d(size, size))\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask\u003dmask, square\u003dTrue, linewidths\u003d.5, cbar_kws\u003d{\"shrink\": 0.5}, ax\u003dax)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reordered correlation matrix\n",
        "\n",
        "An interesting improvement over the correlation matrix is to reorder it by similarity between the variables so that the \"groups\" of variables that are strongly correlated appear close in the matrix."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Generate features and distance matrix.\n",
        "D \u003d corr.values\n",
        "# Compute and plot dendrogram.\n",
        "Y \u003d sch.linkage(D, method\u003d\u0027centroid\u0027)\n",
        "Z \u003d sch.dendrogram(Y, orientation\u003d\u0027right\u0027,no_plot\u003dTrue)\n",
        "# Compute distance matrix.\n",
        "index \u003d Z[\u0027leaves\u0027]\n",
        "D \u003d D[index,:]\n",
        "D \u003d D[:,index]\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask \u003d np.zeros_like(corr, dtype\u003dnp.bool)\n",
        "mask[np.triu_indices_from(mask)] \u003d True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "size \u003d max(10, len(corr.columns)/2.)\n",
        "f, ax \u003d plt.subplots(figsize\u003d(size, size))\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "\n",
        "sns.heatmap(D, mask\u003dmask, square\u003dTrue, linewidths\u003d.5, cbar_kws\u003d{\"shrink\": 0.5}, ax\u003dax)\n",
        "#ax.set(xticks\u003drange(len(corr.columns)), xticklabels\u003dcorr.columns[index], yticks\u003drange(len(corr.columns)), yticklabels\u003dreversed(corr.columns[index]))\n",
        "ax.set_xticklabels(corr.columns[index], rotation\u003d90, ha\u003d\u0027center\u0027);\n",
        "ax.set_yticklabels(corr.columns[index], rotation\u003d0);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scatter matrices \u003ca id\u003d\"scatter-matrix\" /\u003e"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Only generate the scatterplot matrix on a sample\n",
        "df_scatter_samp \u003d df.sample(min(5000, df.shape[0])) # 5000 points maximum on the scatter plot\n",
        "\n",
        "# Take the first 4 numerical variables to plot the scatterplot matrix\n",
        "scatter_matrix_vars \u003d numerical_columns[0:4]\n",
        "\n",
        "# If we have categorical variables, use the categorical variables with the lowest number of modalities\n",
        "# to plot the points of the scatterplot\n",
        "scatter_matrix_color \u003d None\n",
        "\n",
        "cat_cols_with_cards \u003d [(x, df[x].nunique()) for x in categorical_columns]\n",
        "# We don\u0027t want to take a column with only a single modality\n",
        "# and also we don\u0027t want variables with more than 10 modalities (would not really make sense to plot)\n",
        "cat_cols_with_cards_f \u003d [x for x in cat_cols_with_cards if x[1] \u003e\u003d 2 and x[1] \u003c\u003d 10]\n",
        "\n",
        "if len(cat_cols_with_cards_f) \u003e 0:\n",
        "    # We have at least one categorical variable with a good number of modalities, use it\n",
        "    scatter_matrix_color \u003d sorted(cat_cols_with_cards_f, key\u003d lambda c : c[1])[0][0]\n",
        "    \n",
        "print \"We will plot the following numerical variables : %s\" % scatter_matrix_vars\n",
        "if scatter_matrix_color is not None:\n",
        "    print \"Coloring the scatters by: %s\" % scatter_matrix_color"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "# Uncomment this if you want to take manual control over which variables are plotted\n",
        "# scatter_matrix_vars \u003d [\"num1\", \"num2\", \"num3\"]\n",
        "# scatter_matrix_color \u003d \"cat1\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Seaborn (the graphic library) doesn\u0027t like NaNs, so fill the matrix\n",
        "df_filled \u003d df.fillna(0)\n",
        "sns.pairplot(df_filled, vars \u003d scatter_matrix_vars, hue\u003dscatter_matrix_color, height\u003d3, palette\u003d\"husl\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## See the relation between two features, including categorical features \u003ca id\u003d\"two-vars\" /\u003e"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Compute cardinalities of our categorical variables\n",
        "cat_cols_with_cards \u003d [(x, df[x].nunique()) for x in categorical_columns]\n",
        "\n",
        "# For proper display, we only want columns with modalities between 2 and 10\n",
        "cat_cols_with_cards_f \u003d [x for x in cat_cols_with_cards if x[1] \u003e\u003d 2 and x[1] \u003c\u003d 10]\n",
        "\n",
        "nb_suitable_cats \u003d len(cat_cols_with_cards_f)\n",
        "nb_num \u003d len(numerical_columns)\n",
        "\n",
        "if nb_suitable_cats \u003e\u003d 1 and nb_num \u003e\u003d 1:\n",
        "    tf_feat1 \u003d cat_cols_with_cards_f[0][0]\n",
        "    tf_feat2 \u003d numerical_columns[0]\n",
        "\n",
        "elif nb_suitable_cats \u003d\u003d 0 and nb_num \u003e\u003d 2:\n",
        "    tf_feat1 \u003d numerical_columns[0]\n",
        "    tf_feat2 \u003d numerical_columns[1]\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"Failed to automatically select proper variables to plot, please select manually\")\n",
        "\n",
        "print \"Will plot relation between these two features: \u0027%s\u0027 and \u0027%s\u0027\" % (tf_feat1, tf_feat2)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "# Uncomment this to take control on the two variables\n",
        "# tf_feat1 \u003d \"my_feat_1\"\n",
        "# tf_feat2 \u003d \"my_feat_2\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "if tf_feat1 in numerical_columns and tf_feat2 in numerical_columns:\n",
        "    sns.pairplot(df[[tf_feat1, tf_feat2]])\n",
        "    \n",
        "if tf_feat1 in numerical_columns and tf_feat2 in categorical_columns:\n",
        "    sns.FacetGrid(df, col\u003dtf_feat2, col_wrap\u003d5, hue\u003dNone).map(sns.distplot, tf_feat1)\n",
        "    \n",
        "if tf_feat1 in categorical_columns and tf_feat2 in numerical_columns:\n",
        "    sns.FacetGrid(df, col\u003dtf_feat1, col_wrap\u003d5, hue\u003dNone).map(sns.distplot, tf_feat2)\n",
        "    \n",
        "if tf_feat1 in categorical_columns and tf_feat2 in categorical_columns:\n",
        "    tf_list \u003d [tf_feat1, tf_feat2]\n",
        "    tf_unique_count \u003d [df[feat].unique().__len__() for feat in tf_list]\n",
        "    tf_min_loc \u003d tf_unique_count.index(min(tf_unique_count))\n",
        "    sns.FacetGrid(data\u003ddf, col\u003dtf_list[tf_min_loc], col_wrap\u003d5, hue\u003dNone).map(sns.countplot, tf_list[(tf_min_loc+1)%2], order\u003ddf[tf_list[(tf_min_loc+1)%2]].unique())"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "collapsed": true
      },
      "source": [],
      "outputs": []
    }
  ]
}